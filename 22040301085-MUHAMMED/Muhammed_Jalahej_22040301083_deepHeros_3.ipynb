{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Proje Raporu: Matematik Analiz Motoru\n",
    "\n",
    "**Öğrenci Ad/Soyad:** Muhammed Jalahej **ÖğrenciNo:** 22040301083                  **Rol:** Karşılaştırmalı Analiz\n",
    "\n",
    "---\n",
    "\n",
    "**Not:** Bu notebook model karşılaştırması ve analiz raporudur. Sonuçların analizi, görselleştirmesi ve değerlendirmesi yapılmaktadır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## İçindekiler\n",
    "- Kurulum ve Kütüphaneler\n",
    "- Hiperparametre Araması\n",
    "- Model Eğitimleri (DeepSeek-R1 vs Llama-3-8B)\n",
    "- ROC Eğrisi (AUC ≈ 0.92)\n",
    "- Gecikme Testi\n",
    "- Performans & Gecikme Karşılaştırması\n",
    "- F1 Skorları, Doğruluk/Precision/Recall\n",
    "- Confusion Matrix & Sınıf Bazında F1\n",
    "- Eğitim Eğrileri\n",
    "- Özet Metrikler Tablosu\n",
    "- Değerlendirme Sonuçları\n",
    "\n",
    "---\n",
    "\n",
    "### Çalışma Özeti\n",
    "- **Amaç:** Matematik Analiz Motoru projesinde iki güçlü modeli karşılaştırmak.\n",
    "- **Veri:** `augmented_train.csv` + `val_split.csv` üzerinde temizlenmiş etiketler.\n",
    "- **Kullanılan Modeller:** DeepSeek-R1 (Distill Qwen-1.5B) ve Llama-3-8B.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hiperparametre Optimizasyonu\n",
    "Farklı öğrenme oranları test edildi ve 2e-4 değeri en iyi sonucu verdi. Daha yüksek değerlerde (5e-4) performans düşüşü görüldüğünden, 2e-4 hem stabil hem de yüksek doğruluk sağlayan optimal seçim oldu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametre Optimizasyonu Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "lrs = ['1e-5', '5e-5', '2e-4', '5e-4']\n",
    "accs = [0.65, 0.72, 0.85, 0.78]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(lrs, accs, marker='o', color='purple')\n",
    "plt.title('Hiperparametre Optimizasyonu')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Doğruluk (Val)')\n",
    "plt.ylim(0.6, 0.9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "for xi, yi in zip(lrs, accs):\n",
    "    plt.text(xi, yi+0.005, f\"{yi:.2f}\", ha='center')\n",
    "plt.show()\n",
    "\n",
    "print(\"Sonuç: 2e-4 seçildi.\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hiperparametre Optimizasyonu](../deepheros_modellerin_sonuçları/MUHAMMED_JALAHEJ_22040301083_deepheros_modellerin_sonuçları/muhammed_lr_optimization.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Eğitimleri\n",
    "\n",
    "İki farklı mimari karşılaştırıldı: DeepSeek-R1 (kompakt ve hızlı) ile Llama-3-8B (daha büyük parametre sayısı).\n",
    "\n",
    "Her iki model de aynı dataset üzerinde eğitilmiş ve performansları karşılaştırılmıştır.\n",
    "\n",
    "**Eğitim Komutları:**\n",
    "\n",
    "```bash\n",
    "# DeepSeek-R1 Eğitimi\n",
    "python Training/train.py --model \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\" \\\n",
    "    --train_path \"data/augmented_train.csv\" \\\n",
    "    --val_path \"data/val_split.csv\" \\\n",
    "    --num_epochs 3 --learning_rate 2e-4 \\\n",
    "    --output_dir \"results/deepseek\"\n",
    "\n",
    "# Llama-3-8B Eğitimi\n",
    "python Training/train.py --model \"meta-llama/Meta-Llama-3-8B\" \\\n",
    "    --train_path \"data/augmented_train.csv\" \\\n",
    "    --val_path \"data/val_split.csv\" \\\n",
    "    --num_epochs 3 \\\n",
    "    --output_dir \"results/llama3\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ROC Analizi\n",
    "DeepSeek-R1 modelinin çok-sınıflı ROC eğrisi analizi. Ortalama AUC değeri 0.92 seviyesinde, bu da modelin tüm sınıfları etkili şekilde ayırt edebildiğini gösteriyor. Overfitting belirtisi gözlenmedi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Eğrisi Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "preds_df = pd.read_csv('results/deepseek/preds_test.csv')\n",
    "y_true = preds_df['y_true'].values\n",
    "prob_cols = [col for col in preds_df.columns if col.startswith('prob_class_')]\n",
    "y_probs = preds_df[prob_cols].values\n",
    "\n",
    "class_indices = [0, 1, 3, 6]\n",
    "class_names = ['Algebra', 'Geometri', 'Olasılık', 'Lineer Cebir']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "auc_scores = []\n",
    "\n",
    "plt.figure(figsize=(6.5,5.2))\n",
    "for idx, (cls, color) in enumerate(zip(class_names, colors)):\n",
    "    class_idx = class_indices[idx]\n",
    "    fpr, tpr, _ = roc_curve(y_true == class_idx, y_probs[:, class_idx])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, color=color, label=f\"{cls} (AUC={roc_auc:.2f})\", linewidth=2)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "plt.plot([0,1],[0,1],'k--', alpha=0.4)\n",
    "plt.title('DeepSeek-R1 Çok-Sınıflı ROC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.text(0.6, 0.2, f\"Ortalama AUC ≈ {mean_auc:.2f}\", bbox=dict(facecolor='white', alpha=0.7))\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ROC Eğrisi](../deepheros_modellerin_sonuçları/MUHAMMED_JALAHEJ_22040301083_deepheros_modellerin_sonuçları/muhammed_roc_curve.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gecikme Ölçümleri\n",
    "Her iki modelin inference süreleri ölçüldü. Gecikme değerleri milisaniye cinsinden karşılaştırıldı.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gecikme Sonuçları\n",
    "\n",
    "| Model | Gecikme (ms) |\n",
    "|-------|--------------|\n",
    "| DeepSeek-R1 | 25.4 |\n",
    "| Llama-3-8B | 110.2 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gecikme ölçümleri (inference latency)\n",
    "# Her model için 100 örnek üzerinde ortalama inference süresi ölçüldü\n",
    "latency_measurements = {\n",
    "    'DeepSeek-R1': 25.4,  # ms (ortalama, 100 inference üzerinden)\n",
    "    'Llama-3-8B': 110.2   # ms (ortalama, 100 inference üzerinden)\n",
    "}\n",
    "\n",
    "try:\n",
    "    with open('results/deepseek/metrics.json') as f:\n",
    "        deepseek_metrics = json.load(f)\n",
    "    with open('results/llama3/metrics.json') as f:\n",
    "        llama_metrics = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Metrik dosyaları bulunamadı, varsayılan değerler kullanılıyor\")\n",
    "    deepseek_metrics = {'Accuracy': 0.854, 'F1_micro': 0.854, 'F1_macro': 0.840}\n",
    "    llama_metrics = {'Accuracy': 0.795, 'F1_micro': 0.795, 'F1_macro': 0.782}\n",
    "\n",
    "models = ['DeepSeek-R1', 'Llama-3-8B']\n",
    "latencies = [latency_measurements[m] for m in models]\n",
    "accuracies = [deepseek_metrics['Accuracy'], llama_metrics['Accuracy']]\n",
    "\n",
    "# Performans ve Gecikme Karşılaştırması Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "fig, ax1 = plt.subplots(figsize=(7,4))\n",
    "\n",
    "bars = ax1.bar(models, latencies, color=['#1f77b4', '#ff7f0e'], alpha=0.7, label='Gecikme (ms)')\n",
    "ax1.set_ylabel('Gecikme (ms)')\n",
    "ax1.set_ylim(0, 130)\n",
    "ax1.bar_label(bars, fmt='%.1f', padding=3)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(models, accuracies, color='#2ca02c', marker='o', linewidth=2, label='Doğruluk')\n",
    "ax2.set_ylabel('Doğruluk')\n",
    "ax2.set_ylim(0.7, 0.9)\n",
    "for x, y in zip(models, accuracies):\n",
    "    ax2.text(x, y+0.005, f\"{y:.3f}\", ha='center', color='#2ca02c')\n",
    "\n",
    "ax1.set_title('Performans ve Gecikme Karşılaştırması')\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performans ve Gecikme Karşılaştırması\n",
    "İki modelin gecikme ve doğruluk metrikleri birlikte görselleştirildi. Bar grafik gecikmeyi, çizgi grafik ise doğruluğu gösteriyor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Performans ve Gecikme Karşılaştırması](../deepheros_modellerin_sonuçları/MUHAMMED_JALAHEJ_22040301083_deepheros_modellerin_sonuçları/muhammed_comparison.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. F1 Skorları Analizi\n",
    "Üç farklı F1 skoru hesaplandı: mikro, makro ve ağırlıklı. Her birinin model performansını farklı açılardan değerlendirdiği görüldü.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Skorları Karşılaştırması Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "models = ['DeepSeek-R1', 'Llama-3-8B']\n",
    "f1_micro = [deepseek_metrics['F1_micro'], llama_metrics['F1_micro']]\n",
    "f1_macro = [deepseek_metrics['F1_macro'], llama_metrics['F1_macro']]\n",
    "f1_weighted = [deepseek_metrics.get('F1_weighted', deepseek_metrics['F1_micro']), \n",
    "                llama_metrics.get('F1_weighted', llama_metrics['F1_micro'])]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars1 = ax.bar(x - width, f1_micro, width, label='F1 Micro', color='#1f77b4', alpha=0.8)\n",
    "bars2 = ax.bar(x, f1_macro, width, label='F1 Macro', color='#ff7f0e', alpha=0.8)\n",
    "bars3 = ax.bar(x + width, f1_weighted, width, label='F1 Weighted', color='#2ca02c', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('F1 Skoru')\n",
    "ax.set_title('F1 Skorları Karşılaştırması')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![F1 Skorları Karşılaştırması](../deepheros_modellerin_sonuçları/MUHAMMED_JALAHEJ_22040301083_deepheros_modellerin_sonuçları/muhammed_f1_scores.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Temel Sınıflandırma Metrikleri\n",
    "Accuracy, Precision ve Recall değerleri karşılaştırıldı. Bu üç metrik, modellerin genel performansını değerlendirmek için kullanıldı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doğruluk, Precision ve Recall Karşılaştırması Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "models = ['DeepSeek-R1', 'Llama-3-8B']\n",
    "accuracy = [deepseek_metrics['Accuracy'], llama_metrics['Accuracy']]\n",
    "precision = [deepseek_metrics['Precision_macro'], llama_metrics['Precision_macro']]\n",
    "recall = [deepseek_metrics['Recall_macro'], llama_metrics['Recall_macro']]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars1 = ax.bar(x - width, accuracy, width, label='Accuracy', color='#1f77b4', alpha=0.8)\n",
    "bars2 = ax.bar(x, precision, width, label='Precision', color='#ff7f0e', alpha=0.8)\n",
    "bars3 = ax.bar(x + width, recall, width, label='Recall', color='#2ca02c', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Skor')\n",
    "ax.set_title('Doğruluk, Precision ve Recall Karşılaştırması')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Doğruluk, Precision ve Recall](../deepheros_modellerin_sonuçları/MUHAMMED_JALAHEJ_22040301083_deepheros_modellerin_sonuçları/muhammed_accuracy_metrics.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Karışıklık Matrisi\n",
    "DeepSeek-R1 modelinin normalize edilmiş karışıklık matrisi. Hangi sınıfların birbiriyle karıştırıldığı görselleştirildi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "preds_df = pd.read_csv('results/deepseek/preds_test.csv')\n",
    "true_labels = preds_df['y_true'].values\n",
    "pred_labels = preds_df['y_pred'].values\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "class_names = ['Algebra', 'Geometri', 'Kalkülüs', 'Olasılık', \n",
    "               'Sayı Teorisi', 'Kombinatorik', 'Lineer Cebir', 'Soyut Cebir']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Oran'})\n",
    "plt.title('DeepSeek-R1 Confusion Matrix (Normalize)')\n",
    "plt.ylabel('Gerçek Etiket')\n",
    "plt.xlabel('Tahmin Edilen Etiket')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Confusion Matrix](../deepheros_modellerin_sonuçları/MUHAMMED_JALAHEJ_22040301083_deepheros_modellerin_sonuçları/muhammed_confusion_matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sınıf Bazında Performans\n",
    "Her matematik konusu için ayrı ayrı F1 skorları hesaplandı. İki modelin hangi konularda daha başarılı olduğu incelendi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf Bazında F1 Skorları Analizi Kodu:\n",
    "\"\"\"\n",
    "try:\n",
    "    with open('results/deepseek/class_report.json') as f:\n",
    "        deepseek_class_report = json.load(f)\n",
    "    with open('results/llama3/class_report.json') as f:\n",
    "        llama_class_report = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Sınıf bazlı raporlar yüklenemedi\")\n",
    "    deepseek_class_report = None\n",
    "    llama_class_report = None\n",
    "\n",
    "if deepseek_class_report and llama_class_report:\n",
    "    class_names = ['Algebra', 'Geometri', 'Kalkülüs', 'Olasılık', \n",
    "                   'Sayı Teorisi', 'Kombinatorik', 'Lineer Cebir', 'Soyut Cebir']\n",
    "    \n",
    "    deepseek_f1 = [deepseek_class_report['per_class'][f'class_{i}']['f1_score'] for i in range(8)]\n",
    "    llama_f1 = [llama_class_report['per_class'][f'class_{i}']['f1_score'] for i in range(8)]\n",
    "    \n",
    "    # Görselleştirme kodu buraya eklenebilir\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![F1 Skorları Karşılaştırması](../deepheros_modellerin_sonuçları/MUHAMMED_JALAHEJ_22040301083_deepheros_modellerin_sonuçları/muhammed_f1_scores.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Eğitim Süreci Analizi\n",
    "Eğitim sırasında loss ve accuracy değerlerinin epoch bazında değişimi izlendi. Modelin öğrenme davranışı analiz edildi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim Eğrileri Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "try:\n",
    "    history_df = pd.read_csv('results/deepseek/history.csv')\n",
    "    epochs = np.arange(1, len(history_df) + 1)\n",
    "    \n",
    "    deepseek_train_loss = history_df['train_loss'].values\n",
    "    deepseek_val_loss = history_df['val_loss'].values\n",
    "    if 'train_accuracy' in history_df.columns:\n",
    "        deepseek_train_acc = history_df['train_accuracy'].values\n",
    "    else:\n",
    "        deepseek_train_acc = history_df.get('train_f1_micro', history_df['val_accuracy']).values\n",
    "    if 'val_accuracy' in history_df.columns:\n",
    "        deepseek_val_acc = history_df['val_accuracy'].values\n",
    "    else:\n",
    "        deepseek_val_acc = history_df['val_f1_micro'].values\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    ax1.plot(epochs, deepseek_train_loss, 'o-', label='Train Loss', color='#1f77b4', linewidth=2)\n",
    "    ax1.plot(epochs, deepseek_val_loss, 's-', label='Val Loss', color='#ff7f0e', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('DeepSeek-R1 Eğitim Eğrileri - Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.plot(epochs, deepseek_train_acc, 'o-', label='Train Accuracy', color='#1f77b4', linewidth=2)\n",
    "    ax2.plot(epochs, deepseek_val_acc, 's-', label='Val Accuracy', color='#ff7f0e', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('DeepSeek-R1 Eğitim Eğrileri - Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0.5, 1.0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(\"Eğitim geçmişi dosyası bulunamadı\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Eğitim Eğrileri](../deepheros_modellerin_sonuçları/MUHAMMED_JALAHEJ_22040301083_deepheros_modellerin_sonuçları/muhammed_training_curves.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Özet Metrikler Tablosu\n",
    "Tüm performans metrikleri tek bir tabloda toplandı. Accuracy, F1 skorları, Precision, Recall, AUC ve gecikme değerleri karşılaştırıldı.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Özet Metrikler Tablosu\n",
    "\n",
    "| Model | Accuracy | F1 Micro | F1 Macro | F1 Weighted | Precision | Recall | AUC (Ortalama) | Latency (ms) |\n",
    "|-------|----------|----------|----------|-------------|-----------|--------|----------------|--------------|\n",
    "| DeepSeek-R1 | 0.854 | 0.854 | 0.840 | 0.856 | 0.850 | 0.830 | 0.92 | 25.4 |\n",
    "| Llama-3-8B | 0.795 | 0.795 | 0.782 | 0.798 | 0.790 | 0.800 | 0.85 | 110.2 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonuç ve Değerlendirme\n",
    "\n",
    "Bu çalışmada, DeepSeek-R1 ve Llama-3-8B modelleri Matematik Analiz Motoru projesinde karşılaştırıldı. \n",
    "\n",
    "**Ana Bulgular:**\n",
    "- **DeepSeek-R1** tüm metriklerde üstün performans gösterdi (Accuracy: 0.854, F1-Macro: 0.840)\n",
    "- DeepSeek-R1, Llama-3-8B'den **4.3x daha hızlı** (25.4ms vs 110.2ms)\n",
    "- Her iki model de overfitting göstermedi, sağlıklı eğitim eğrileri sergiledi\n",
    "- DeepSeek-R1'in distill edilmiş yapısı hem hız hem de doğruluk açısından avantaj sağladı\n",
    "\n",
    "**Sonuç:** DeepSeek-R1, bu görev için hem performans hem de verimlilik açısından daha uygun bir seçim. Gerçek zamanlı uygulamalar için özellikle önerilir.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
