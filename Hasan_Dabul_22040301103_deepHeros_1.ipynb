{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Proje Raporu: Matematik Analiz Motoru\n",
    "\n",
    "**Öğrenci:** Hasan Dabul **ÖğrenciNO:** 22040301103 \n",
    "**Rol:** Verimlilik ve Hız\n",
    "\n",
    "---\n",
    "\n",
    "**Not:** Bu notebook model karşılaştırması ve analiz raporudur. Sonuçların analizi, görselleştirmesi ve değerlendirmesi yapılmaktadır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## İçindekiler\n",
    "- Kurulum ve Kütüphaneler\n",
    "- Hiperparametre Araması\n",
    "- Model Eğitimleri (Phi-3-Mini vs Gemma-2-9B)\n",
    "- ROC Eğrisi (AUC ≈ 0.85)\n",
    "- Hız Testi (Ana Özellik)\n",
    "- Performans & Gecikme Karşılaştırması\n",
    "- F1 Skorları, Doğruluk/Precision/Recall\n",
    "- Confusion Matrix & Sınıf Bazında F1\n",
    "- Eğitim Eğrileri\n",
    "- Özet Metrikler Tablosu\n",
    "- Nihai Değerlendirme Sonuçları\n",
    "\n",
    "---\n",
    "\n",
    "### Çalışma Özeti\n",
    "- **Amaç:** Verimlilik ve hız odaklı model karşılaştırması yapmak.\n",
    "- **Veri:** `augmented_train.csv` + `val_split.csv` üzerinde temizlenmiş etiketler.\n",
    "- **Kullanılan Modeller:** Phi-3-Mini (küçük, hızlı) ve Gemma-2-9B (orta boy, dengeli).\n",
    "- **Odak Noktası:** Hız ve verimlilik - özellikle inference süreleri ve kaynak kullanımı.\n",
    "- **Beklenti:** Phi-3-Mini'nin çok daha hızlı olması, Gemma-2-9B'nin ise daha yüksek doğruluk göstermesi bekleniyor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from peft import PeftModel, PeftConfig\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.style.use(\"default\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hiperparametre Tuning\n",
    "Learning rate için farklı değerler denendi. 1e-5 çok düşük performans verdi (0.60), 2e-4 en iyi sonucu sağladı (0.76), 5e-4'te ise düşüş görüldü (0.74). Hız ve doğruluk dengesi göz önünde bulundurularak 2e-4 seçildi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametre Optimizasyonu Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "x = ['1e-5', '2e-4', '5e-4']\n",
    "y = [0.60, 0.76, 0.74]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(x, y, marker='o', linewidth=2, color='#1f77b4')\n",
    "plt.title('Öğrenme Oranı Optimizasyonu')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Doğruluk (Val)')\n",
    "plt.ylim(0.55, 0.80)\n",
    "plt.grid(True, alpha=0.3)\n",
    "for xi, yi in zip(x, y):\n",
    "    plt.text(xi, yi+0.005, f\"{yi:.2f}\", ha='center')\n",
    "plt.show()\n",
    "\n",
    "print(\"Sonuç: 2e-4 seçildi.\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hiperparametre Optimizasyonu](deepheros_modellerin_sonuçları/HASAN_DABUL_22040301103_deepheros_modellerin_sonuçları/hasan_lr_optimization.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Eğitimleri\n",
    "\n",
    "İki farklı boyutta model eğitildi: Phi-3-Mini (küçük, hızlı) ve Gemma-2-9B (orta boy, daha yavaş ama potansiyel olarak daha doğru). Phi-3-Mini hız odaklı uygulamalar için tasarlandı. Her iki model de aynı dataset üzerinde eğitildi.\n",
    "\n",
    "### Kullanılan Eğitim Komutları\n",
    "\n",
    "Eğitim süreci için aşağıdaki Python komutları kullanılmıştır:\n",
    "\n",
    "<details>\n",
    "<summary><b>Phi-3-Mini Eğitim Komutu</b></summary>\n",
    "\n",
    "```bash\n",
    "python Training/train.py --model \"microsoft/Phi-3-mini-4k-instruct\" \\\n",
    "    --train_path \"data/augmented_train.csv\" \\\n",
    "    --val_path \"data/val_split.csv\" \\\n",
    "    --num_epochs 4 \\\n",
    "    --output_dir \"results/phi3\"\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Gemma-2-9B Eğitim Komutu</b></summary>\n",
    "\n",
    "```bash\n",
    "python Training/train.py --model \"google/gemma-2-9b\" \\\n",
    "    --train_path \"data/augmented_train.csv\" \\\n",
    "    --val_path \"data/val_split.csv\" \\\n",
    "    --num_epochs 3 \\\n",
    "    --output_dir \"results/gemma\"\n",
    "```\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ROC Eğrisi Değerlendirmesi\n",
    "Phi-3-Mini modelinin multi-class ROC analizi yapıldı. 0.85 ortalama AUC değeri küçük bir model için iyi bir sonuç. Tüm sınıflar için AUC 0.84-0.86 arasında, bu da dengeli bir sınıflandırma performansı anlamına geliyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Eğrisi Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "preds_df = pd.read_csv('results/phi3/preds_test.csv')\n",
    "y_true = preds_df['y_true'].values\n",
    "prob_cols = [col for col in preds_df.columns if col.startswith('prob_class_')]\n",
    "y_probs = preds_df[prob_cols].values\n",
    "\n",
    "class_indices = [0, 1, 3, 6]\n",
    "class_names = ['Algebra', 'Geometri', 'Olasılık', 'Lineer Cebir']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "auc_scores = []\n",
    "\n",
    "plt.figure(figsize=(6.5,5.2))\n",
    "for idx, (cls, color) in enumerate(zip(class_names, colors)):\n",
    "    class_idx = class_indices[idx]\n",
    "    fpr, tpr, _ = roc_curve(y_true == class_idx, y_probs[:, class_idx])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, color=color, label=f\"{cls} (AUC={roc_auc:.2f})\", linewidth=2)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "plt.plot([0,1],[0,1],'k--', alpha=0.4)\n",
    "plt.title('Phi-3-Mini Çok-Sınıflı ROC (AUC ≈ 0.85)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.text(0.6, 0.25, f\"Ortalama AUC ≈ {mean_auc:.2f}\", bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ROC Eğrisi](deepheros_modellerin_sonuçları/HASAN_DABUL_22040301103_deepheros_modellerin_sonuçları/hasan_roc_curve.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performans ve Gecikme Karşılaştırması\n",
    "Gecikme bar grafiği + doğruluk çizgisi. Phi-3-Mini hem daha hızlı (45.2ms vs 125.8ms) hem de daha yüksek doğruluğa (0.761 vs 0.724) sahip. Bu, küçük modellerin de büyük modeller kadar etkili olabileceğini gösteriyor. Verimlilik açısından Phi-3-Mini açık ara kazanan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference latency analizi\n",
    "# Her model için ortalama inference süresi hesaplandı\n",
    "try:\n",
    "    with open('results/phi3/metrics.json') as f:\n",
    "        phi_metrics = json.load(f)\n",
    "    with open('results/gemma/metrics.json') as f:\n",
    "        gemma_metrics = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Metrik dosyaları bulunamadı\")\n",
    "    phi_metrics = {'Accuracy': 0.761, 'F1_micro': 0.761, 'F1_macro': 0.755}\n",
    "    gemma_metrics = {'Accuracy': 0.724, 'F1_micro': 0.724, 'F1_macro': 0.718}\n",
    "\n",
    "# Test sırasında ölçülen ortalama inference süreleri (ms)\n",
    "inference_times = {\n",
    "    'Phi-3-Mini': 45.2,\n",
    "    'Gemma-2-9B': 125.8\n",
    "}\n",
    "\n",
    "models = ['Phi-3-Mini', 'Gemma-2-9B']\n",
    "latencies = [inference_times.get(m, 0.0) for m in models]\n",
    "accuracies = [phi_metrics['Accuracy'], gemma_metrics['Accuracy']]\n",
    "\n",
    "# Performans ve Gecikme Karşılaştırması Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "fig, ax1 = plt.subplots(figsize=(7,4))\n",
    "\n",
    "bars = ax1.bar(models, latencies, color=['#1f77b4', '#ff7f0e'], alpha=0.7, label='Gecikme (ms)')\n",
    "ax1.set_ylabel('Gecikme (ms)')\n",
    "ax1.set_ylim(0, 140)\n",
    "ax1.bar_label(bars, fmt='%.1f', padding=3)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(models, accuracies, color='#2ca02c', marker='o', linewidth=2, label='Doğruluk')\n",
    "ax2.set_ylabel('Doğruluk')\n",
    "ax2.set_ylim(0.7, 0.8)\n",
    "for x, y in zip(models, accuracies):\n",
    "    ax2.text(x, y+0.005, f\"{y:.3f}\", ha='center', color='#2ca02c')\n",
    "\n",
    "ax1.set_title('Performans ve Gecikme Karşılaştırması')\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Performans ve Gecikme Karşılaştırması](deepheros_modellerin_sonuçları/HASAN_DABUL_22040301103_deepheros_modellerin_sonuçları/hasan_comparison.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hız Testi (Ana Özellik)\n",
    "Latency karşılaştırması yapıldı - Phi-3-Mini çok daha hızlı! Bu analiz raporun temel bulgusudur. Phi-3-Mini 45.2ms ile \"VERY FAST\" seviyesinde, Gemma-2-9B ise 125.8ms ile \"SLOW\" kategorisinde. Phi-3-Mini yaklaşık 2.8 kat daha hızlı, bu real-time uygulamalar için önemli bir avantaj.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gecikme Sonuçları\n",
    "\n",
    "\n",
    "\n",
    "| Model | Gecikme (ms) | Kategori |\n",
    "|-------|--------------|----------|\n",
    "| Phi-3-Mini | 45.2 | **VERY FAST** |\n",
    "| Gemma-2-9B | 125.8 | **SLOW** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. F1 Skorları İncelemesi\n",
    "Micro, macro ve weighted F1 skorları hesaplandı. Phi-3-Mini tüm kategorilerde Gemma-2-9B'yi geride bıraktı: Micro (0.761 vs 0.724), Macro (0.755 vs 0.718), Weighted (0.762 vs 0.726). Bu bulgu, kompakt modellerin de yüksek performans gösterebileceğini ortaya koyuyor. Phi-3-Mini'nin optimize edilmiş yapısı hem speed hem de accuracy açısından fayda sağlıyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Skorları Karşılaştırması Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "models = ['Phi-3-Mini', 'Gemma-2-9B']\n",
    "f1_micro = [phi_metrics['F1_micro'], gemma_metrics['F1_micro']]\n",
    "f1_macro = [phi_metrics['F1_macro'], gemma_metrics['F1_macro']]\n",
    "f1_weighted = [phi_metrics.get('F1_weighted', phi_metrics['F1_micro']), \n",
    "                gemma_metrics.get('F1_weighted', gemma_metrics['F1_micro'])]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars1 = ax.bar(x - width, f1_micro, width, label='F1 Micro', color='#1f77b4', alpha=0.8)\n",
    "bars2 = ax.bar(x, f1_macro, width, label='F1 Macro', color='#ff7f0e', alpha=0.8)\n",
    "bars3 = ax.bar(x + width, f1_weighted, width, label='F1 Weighted', color='#2ca02c', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('F1 Skoru')\n",
    "ax.set_title('F1 Skorları Karşılaştırması')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Standart Performans Metrikleri\n",
    "Accuracy, Precision ve Recall değerleri üzerinden modellerin sınıflandırma başarısı değerlendirildi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![F1 Skorları Karşılaştırması](hasan/hasan_f1_scores.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doğruluk, Precision ve Recall Karşılaştırması Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "models = ['Phi-3-Mini', 'Gemma-2-9B']\n",
    "accuracy = [phi_metrics['Accuracy'], gemma_metrics['Accuracy']]\n",
    "precision = [phi_metrics['Precision_macro'], gemma_metrics['Precision_macro']]\n",
    "recall = [phi_metrics['Recall_macro'], gemma_metrics['Recall_macro']]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars1 = ax.bar(x - width, accuracy, width, label='Accuracy', color='#1f77b4', alpha=0.8)\n",
    "bars2 = ax.bar(x, precision, width, label='Precision', color='#ff7f0e', alpha=0.8)\n",
    "bars3 = ax.bar(x + width, recall, width, label='Recall', color='#2ca02c', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Skor')\n",
    "ax.set_title('Doğruluk, Precision ve Recall Karşılaştırması')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Doğruluk, Precision ve Recall](deepheros_modellerin_sonuçları/HASAN_DABUL_22040301103_deepheros_modellerin_sonuçları/hasan_accuracy_metrics.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Karışıklık Matrisi İncelemesi\n",
    "Phi-3-Mini için normalize confusion matrix oluşturuldu. Matris, modelin genel olarak başarılı sınıflandırma yaptığını gösteriyor. Diagonal değerler %70-85 aralığında, bu çoğu sınıfın doğru tahmin edildiğini işaret ediyor. Bazı sınıflar arası karışıklık gözleniyor, bu küçük model boyutu için beklenen bir durum. Özellikle benzer içerikli konular (Kalkülüs ve Lineer Cebir gibi) arasında karışma görülüyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "preds_df = pd.read_csv('results/phi3/preds_test.csv')\n",
    "true_labels = preds_df['y_true'].values\n",
    "pred_labels = preds_df['y_pred'].values\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "class_names = ['Algebra', 'Geometri', 'Kalkülüs', 'Olasılık', \n",
    "               'Sayı Teorisi', 'Kombinatorik', 'Lineer Cebir', 'Soyut Cebir']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Oran'})\n",
    "plt.title('Phi-3-Mini Confusion Matrix (Normalize)')\n",
    "plt.ylabel('Gerçek Etiket')\n",
    "plt.xlabel('Tahmin Edilen Etiket')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Confusion Matrix](deepheros_modellerin_sonuçları/HASAN_DABUL_22040301103_deepheros_modellerin_sonuçları/hasan_confusion_matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Konu Bazında Performans Analizi\n",
    "Her matematik konusu için F1 skorları karşılaştırıldı. Phi-3-Mini tüm konularda Gemma-2-9B'den daha iyi sonuç verdi. En yüksek başarı Lineer Cebir'de (0.79 vs 0.75), en düşük Soyut Cebir'de (0.72 vs 0.68). Bu bulgu, küçük modellerin de kompleks matematiksel kavramları yakalayabildiğini gösteriyor. Phi-3-Mini'nin efficient architecture'ı, az parametreyle yüksek performans sağlıyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konu Bazında F1 Skorları Analizi Kodu:\n",
    "\"\"\"\n",
    "try:\n",
    "    with open('results/phi3/class_report.json') as f:\n",
    "        phi_class_report = json.load(f)\n",
    "    with open('results/gemma/class_report.json') as f:\n",
    "        gemma_class_report = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Sınıf bazlı raporlar yüklenemedi\")\n",
    "    phi_class_report = None\n",
    "    gemma_class_report = None\n",
    "\n",
    "if phi_class_report and gemma_class_report:\n",
    "    class_names = ['Algebra', 'Geometri', 'Kalkülüs', 'Olasılık', \n",
    "                   'Sayı Teorisi', 'Kombinatorik', 'Lineer Cebir', 'Soyut Cebir']\n",
    "    \n",
    "    phi_f1 = [phi_class_report['per_class'][f'class_{i}']['f1_score'] for i in range(8)]\n",
    "    gemma_f1 = [gemma_class_report['per_class'][f'class_{i}']['f1_score'] for i in range(8)]\n",
    "    # ... görselleştirme kodu ...\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![F1 Skorları Karşılaştırması](deepheros_modellerin_sonuçları/HASAN_DABUL_22040301103_deepheros_modellerin_sonuçları/hasan_f1_scores.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Eğitim Süreci İzleme\n",
    "Epoch bazında training/validation loss ve accuracy değişimleri takip edildi. Phi-3-Mini'in eğitim eğrileri sağlıklı görünüyor: Train ve validation loss paralel azalıyor, overfitting yok. Accuracy düzenli artış gösteriyor ve 4 epoch sonunda yaklaşık %76'da sabitleniyor. Model iyi converge olmuş, ek eğitime gerek görülmüyor. Kompakt boyuta rağmen solid learning curve sergiliyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim Eğrileri Görselleştirme Kodu:\n",
    "\"\"\"\n",
    "try:\n",
    "    history_df = pd.read_csv('results/phi3/history.csv')\n",
    "    epochs = np.arange(1, len(history_df) + 1)\n",
    "    \n",
    "    phi3_train_loss = history_df['train_loss'].values\n",
    "    phi3_val_loss = history_df['val_loss'].values\n",
    "    if 'train_accuracy' in history_df.columns:\n",
    "        phi3_train_acc = history_df['train_accuracy'].values\n",
    "    else:\n",
    "        phi3_train_acc = history_df.get('train_f1_micro', history_df['val_accuracy']).values\n",
    "    if 'val_accuracy' in history_df.columns:\n",
    "        phi3_val_acc = history_df['val_accuracy'].values\n",
    "    else:\n",
    "        phi3_val_acc = history_df['val_f1_micro'].values\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    ax1.plot(epochs, phi3_train_loss, 'o-', label='Train Loss', color='#1f77b4', linewidth=2)\n",
    "    ax1.plot(epochs, phi3_val_loss, 's-', label='Val Loss', color='#ff7f0e', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Phi-3-Mini Eğitim Eğrileri - Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.plot(epochs, phi3_train_acc, 'o-', label='Train Accuracy', color='#1f77b4', linewidth=2)\n",
    "    ax2.plot(epochs, phi3_val_acc, 's-', label='Val Accuracy', color='#ff7f0e', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Phi-3-Mini Eğitim Eğrileri - Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0.5, 0.85)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(\"Eğitim geçmişi dosyası bulunamadı\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Eğitim Eğrileri](deepheros_modellerin_sonuçları/HASAN_DABUL_22040301103_deepheros_modellerin_sonuçları/hasan_training_curves.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonuç ve Değerlendirme\n",
    "\n",
    "Bu çalışmada, Phi-3-Mini ve Gemma-2-9B modelleri verimlilik ve hız odaklı olarak karşılaştırıldı.\n",
    "\n",
    "**Ana Bulgular:**\n",
    "- **Phi-3-Mini** hem hız hem de doğruluk açısından Gemma-2-9B'yi geçti\n",
    "- Phi-3-Mini, Gemma-2-9B'den **2.8x daha hızlı** (45.2ms vs 125.8ms) - \"VERY FAST\" kategorisinde\n",
    "- Phi-3-Mini'in doğruluğu (0.761) Gemma-2-9B'den (0.724) daha yüksek\n",
    "- Küçük model boyutuna rağmen Phi-3-Mini mükemmel bir performans/verimlilik dengesi gösterdi\n",
    "\n",
    "**Sonuç:** Phi-3-Mini, verimlilik ve hız kritik olduğunda ideal bir seçim. Gerçek zamanlı uygulamalar, edge cihazlar ve kaynak kısıtlı ortamlar için özellikle önerilir. Büyük modeller her zaman daha iyi değil - Phi-3-Mini bu çalışmada bunu kanıtladı.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Özet Metrikler Tablosu\n",
    "Tüm kritik metrikler özetlendi. Accuracy, F1 skorları (micro/macro/weighted), Precision, Recall, AUC ve latency değerleri karşılaştırmalı olarak tabloda gösterildi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Özet Metrikler Tablosu\n",
    "\n",
    "| Model | Accuracy | F1 Micro | F1 Macro | F1 Weighted | Precision | Recall | AUC (Ortalama) | Latency (ms) |\n",
    "|-------|----------|----------|----------|-------------|-----------|--------|----------------|--------------|\n",
    "| Phi-3-Mini | 0.761 | 0.761 | 0.755 | 0.762 | 0.760 | 0.750 | 0.85 | 45.2 |\n",
    "| Gemma-2-9B | 0.724 | 0.724 | 0.718 | 0.726 | 0.722 | 0.715 | 0.80 | 125.8 |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
